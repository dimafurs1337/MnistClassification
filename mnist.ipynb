{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Dense, Flatten, AveragePooling2D, Activation, ELU, BatchNormalization, Layer, Lambda, LeakyReLU\n",
    "from keras.optimizers import Adadelta, Adam, RMSprop\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.datasets.mnist import load_data as load\n",
    "from keras.models import load_model\n",
    "import pandas as pd\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.loadtxt(\"train.csv\", delimiter=',', skiprows=1)\n",
    "test_data = np.loadtxt(\"test.csv\", delimiter=',', skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset: (42000, 784)\n",
      "Size of test dataset: (28000, 784)\n"
     ]
    }
   ],
   "source": [
    "train_input = train_data[:, 1:].astype('float32')/255\n",
    "train_target = train_data[:, 0].astype('int32')\n",
    "print(\"Size of train dataset: {}\".format(train_input.shape))\n",
    "\n",
    "test_input = test_data.astype('float32')/255\n",
    "print(\"Size of test dataset: {}\".format(test_input.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = train_input.reshape(train_input.shape[0], 28, 28, 1)\n",
    "test_input = test_input.reshape(test_input.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = to_categorical(train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), padding='same', input_shape=(28,28,1)))\n",
    "    model.add(BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), padding='same'))\n",
    "    model.add(BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    model.add(Conv2D(128, kernel_size=(3, 3), padding='same'))\n",
    "    model.add(BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Conv2D(128, kernel_size=(3, 3), padding='same'))\n",
    "    model.add(BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    model.add(Conv2D(256, kernel_size=(3, 3), padding='same'))\n",
    "    model.add(BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Conv2D(256, kernel_size=(3, 3), padding='same'))\n",
    "    model.add(BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = RMSprop(lr=0.001, rho=0.92, epsilon=1e-08, decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adm = Adam(learning_rate=1e-3, beta_1=0.92, beta_2=0.999, amsgrad=False)\n",
    "model = build_model()\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = adm, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_validation, y_train, y_validation = train_test_split(train_input, train_target, test_size=0.2 , random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen = ImageDataGenerator(\n",
    "        featurewise_center=False,\n",
    "        samplewise_center=False,\n",
    "        featurewise_std_normalization=False, \n",
    "        samplewise_std_normalization=False,\n",
    "        zca_whitening=False,  \n",
    "        rotation_range=10,  \n",
    "        zoom_range = 0.1,  \n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1, \n",
    "        horizontal_flip=False, \n",
    "        vertical_flip=False)  \n",
    "\n",
    "data_gen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.25, \n",
    "                                            min_lr=0.00001)\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', min_delta=1e-1, verbose=1, patience=100, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "468/468 [==============================] - 69s 147ms/step - loss: 0.2388 - accuracy: 0.9235 - val_loss: 0.0410 - val_accuracy: 0.9795\n",
      "Epoch 2/50\n",
      "468/468 [==============================] - 64s 137ms/step - loss: 0.0811 - accuracy: 0.9743 - val_loss: 0.0042 - val_accuracy: 0.9880\n",
      "Epoch 3/50\n",
      "468/468 [==============================] - 64s 137ms/step - loss: 0.0637 - accuracy: 0.9800 - val_loss: 0.3948 - val_accuracy: 0.9864\n",
      "Epoch 4/50\n",
      "468/468 [==============================] - 64s 138ms/step - loss: 0.0572 - accuracy: 0.9818 - val_loss: 2.5364e-04 - val_accuracy: 0.9886\n",
      "Epoch 5/50\n",
      "468/468 [==============================] - 64s 137ms/step - loss: 0.0495 - accuracy: 0.9848 - val_loss: 0.0047 - val_accuracy: 0.9899\n",
      "Epoch 6/50\n",
      "468/468 [==============================] - 64s 137ms/step - loss: 0.0475 - accuracy: 0.9854 - val_loss: 0.0012 - val_accuracy: 0.9918\n",
      "Epoch 7/50\n",
      "468/468 [==============================] - 64s 137ms/step - loss: 0.0443 - accuracy: 0.9865 - val_loss: 0.1412 - val_accuracy: 0.9885\n",
      "Epoch 8/50\n",
      "468/468 [==============================] - 64s 137ms/step - loss: 0.0405 - accuracy: 0.9874 - val_loss: 0.0172 - val_accuracy: 0.9928\n",
      "Epoch 9/50\n",
      "468/468 [==============================] - 64s 137ms/step - loss: 0.0373 - accuracy: 0.9887 - val_loss: 0.0013 - val_accuracy: 0.9929\n",
      "Epoch 10/50\n",
      "468/468 [==============================] - 64s 137ms/step - loss: 0.0375 - accuracy: 0.9886 - val_loss: 0.0029 - val_accuracy: 0.9917\n",
      "Epoch 11/50\n",
      "468/468 [==============================] - 64s 137ms/step - loss: 0.0334 - accuracy: 0.9893 - val_loss: 0.0249 - val_accuracy: 0.9923\n",
      "Epoch 12/50\n",
      "468/468 [==============================] - 64s 137ms/step - loss: 0.0336 - accuracy: 0.9895 - val_loss: 6.1337e-04 - val_accuracy: 0.9929\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 13/50\n",
      "468/468 [==============================] - 64s 137ms/step - loss: 0.0238 - accuracy: 0.9929 - val_loss: 6.6997e-04 - val_accuracy: 0.9956\n",
      "Epoch 14/50\n",
      "468/468 [==============================] - 64s 137ms/step - loss: 0.0210 - accuracy: 0.9935 - val_loss: 0.0064 - val_accuracy: 0.9956\n",
      "Epoch 15/50\n",
      "468/468 [==============================] - 64s 137ms/step - loss: 0.0196 - accuracy: 0.9940 - val_loss: 0.0019 - val_accuracy: 0.9956\n",
      "Epoch 16/50\n",
      "468/468 [==============================] - 64s 137ms/step - loss: 0.0185 - accuracy: 0.9942 - val_loss: 0.0017 - val_accuracy: 0.9956\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 17/50\n",
      "468/468 [==============================] - 64s 137ms/step - loss: 0.0159 - accuracy: 0.9951 - val_loss: 2.2246e-05 - val_accuracy: 0.9957\n",
      "Epoch 18/50\n",
      "468/468 [==============================] - 64s 137ms/step - loss: 0.0158 - accuracy: 0.9953 - val_loss: 6.9683e-05 - val_accuracy: 0.9959\n",
      "Epoch 19/50\n",
      "468/468 [==============================] - 64s 138ms/step - loss: 0.0142 - accuracy: 0.9957 - val_loss: 0.0203 - val_accuracy: 0.9970\n",
      "Epoch 20/50\n",
      "468/468 [==============================] - 64s 137ms/step - loss: 0.0145 - accuracy: 0.9956 - val_loss: 5.1933e-04 - val_accuracy: 0.9960\n",
      "Epoch 21/50\n",
      "468/468 [==============================] - 64s 137ms/step - loss: 0.0141 - accuracy: 0.9955 - val_loss: 6.3516e-05 - val_accuracy: 0.9964\n",
      "Epoch 22/50\n",
      "468/468 [==============================] - 64s 137ms/step - loss: 0.0145 - accuracy: 0.9958 - val_loss: 3.1016e-04 - val_accuracy: 0.9957\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 23/50\n",
      "468/468 [==============================] - 64s 137ms/step - loss: 0.0145 - accuracy: 0.9957 - val_loss: 2.7652e-05 - val_accuracy: 0.9963\n",
      "Epoch 24/50\n",
      "468/468 [==============================] - 64s 138ms/step - loss: 0.0138 - accuracy: 0.9958 - val_loss: 0.0024 - val_accuracy: 0.9965\n",
      "Epoch 25/50\n",
      "468/468 [==============================] - 64s 137ms/step - loss: 0.0137 - accuracy: 0.9959 - val_loss: 1.8759e-04 - val_accuracy: 0.9962\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 26/50\n",
      "468/468 [==============================] - 64s 137ms/step - loss: 0.0133 - accuracy: 0.9960 - val_loss: 4.9830e-04 - val_accuracy: 0.9961\n",
      "Epoch 27/50\n",
      "468/468 [==============================] - 64s 137ms/step - loss: 0.0125 - accuracy: 0.9960 - val_loss: 0.0085 - val_accuracy: 0.9965\n",
      "Epoch 28/50\n",
      "468/468 [==============================] - 64s 137ms/step - loss: 0.0131 - accuracy: 0.9960 - val_loss: 0.0010 - val_accuracy: 0.9970\n",
      "Epoch 29/50\n",
      "468/468 [==============================] - 64s 137ms/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.0072 - val_accuracy: 0.9963\n",
      "Epoch 30/50\n",
      "468/468 [==============================] - 64s 137ms/step - loss: 0.0123 - accuracy: 0.9961 - val_loss: 0.0416 - val_accuracy: 0.9964\n",
      "Epoch 31/50\n",
      "468/468 [==============================] - 64s 137ms/step - loss: 0.0136 - accuracy: 0.9958 - val_loss: 1.6383e-05 - val_accuracy: 0.9959\n",
      "Epoch 32/50\n",
      "468/468 [==============================] - 64s 137ms/step - loss: 0.0127 - accuracy: 0.9962 - val_loss: 0.2148 - val_accuracy: 0.9969\n",
      "Epoch 33/50\n",
      "468/468 [==============================] - 64s 137ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.0015 - val_accuracy: 0.9959\n",
      "Epoch 34/50\n",
      "468/468 [==============================] - 64s 137ms/step - loss: 0.0125 - accuracy: 0.9961 - val_loss: 0.0360 - val_accuracy: 0.9970\n",
      "Epoch 35/50\n",
      "468/468 [==============================] - 64s 137ms/step - loss: 0.0124 - accuracy: 0.9962 - val_loss: 0.0027 - val_accuracy: 0.9964\n",
      "Epoch 36/50\n",
      "468/468 [==============================] - 64s 137ms/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 7.1074e-05 - val_accuracy: 0.9968\n",
      "Epoch 37/50\n",
      "468/468 [==============================] - 64s 137ms/step - loss: 0.0129 - accuracy: 0.9960 - val_loss: 0.0055 - val_accuracy: 0.9963\n",
      "Epoch 38/50\n",
      "468/468 [==============================] - 64s 137ms/step - loss: 0.0133 - accuracy: 0.9958 - val_loss: 0.0202 - val_accuracy: 0.9963\n",
      "Epoch 39/50\n",
      "468/468 [==============================] - 64s 137ms/step - loss: 0.0130 - accuracy: 0.9957 - val_loss: 4.6437e-05 - val_accuracy: 0.9968\n",
      "Epoch 40/50\n",
      "468/468 [==============================] - 64s 137ms/step - loss: 0.0128 - accuracy: 0.9960 - val_loss: 4.2124e-04 - val_accuracy: 0.9970\n",
      "Epoch 41/50\n",
      "468/468 [==============================] - 64s 137ms/step - loss: 0.0126 - accuracy: 0.9962 - val_loss: 4.2176e-04 - val_accuracy: 0.9963\n",
      "Epoch 42/50\n",
      "468/468 [==============================] - 64s 137ms/step - loss: 0.0130 - accuracy: 0.9961 - val_loss: 0.0011 - val_accuracy: 0.9960\n",
      "Epoch 43/50\n",
      "468/468 [==============================] - 64s 137ms/step - loss: 0.0120 - accuracy: 0.9961 - val_loss: 0.0023 - val_accuracy: 0.9969\n",
      "Epoch 44/50\n",
      "468/468 [==============================] - 64s 138ms/step - loss: 0.0126 - accuracy: 0.9961 - val_loss: 7.7920e-05 - val_accuracy: 0.9966\n",
      "Epoch 45/50\n",
      "468/468 [==============================] - 64s 137ms/step - loss: 0.0126 - accuracy: 0.9959 - val_loss: 5.4425e-05 - val_accuracy: 0.9967\n",
      "Epoch 46/50\n",
      "468/468 [==============================] - 64s 137ms/step - loss: 0.0121 - accuracy: 0.9963 - val_loss: 0.0058 - val_accuracy: 0.9962\n",
      "Epoch 47/50\n",
      "468/468 [==============================] - 64s 137ms/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 1.0922e-05 - val_accuracy: 0.9965\n",
      "Epoch 48/50\n",
      "468/468 [==============================] - 64s 138ms/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 1.3441e-04 - val_accuracy: 0.9968\n",
      "Epoch 49/50\n",
      "468/468 [==============================] - 64s 137ms/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 2.1013e-04 - val_accuracy: 0.9962\n",
      "Epoch 50/50\n",
      "468/468 [==============================] - 65s 138ms/step - loss: 0.0125 - accuracy: 0.9960 - val_loss: 0.3961 - val_accuracy: 0.9967\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(data_gen.flow(x_train, y_train, batch_size=batch_size), \n",
    "                              validation_data=data_gen.flow(x_validation, y_validation, batch_size=batch_size), \n",
    "                              steps_per_epoch=len(x_train)//batch_size, epochs=epochs, callbacks=[learning_rate_reduction, es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.predict(test_input)\n",
    "results = np.argmax(results,axis = 1)\n",
    "\n",
    "results = pd.Series(results,name=\"Label\")\n",
    "submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n",
    "submission.to_csv(\"my_submission.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
